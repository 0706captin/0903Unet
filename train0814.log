start_time: 2020-08-14 23:03:01
Starting epoch 1/150.
/home/huangjq/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Epoch finished ! Loss: 0.23831874705277956
/home/huangjq/PyCharmCode/4_project/1_UNet/B4_attUnetv4/utils/criterion.py:146: RuntimeWarning: invalid value encountered in true_divide
  acc_cls = np.diag(hist) / hist.sum(axis=1)
train_acc:0.20354749720140364 || test_acc:0.20645750584272882
Starting epoch 2/150.
Epoch finished ! Loss: 0.2328639695277581
train_acc:0.20495814876798152 || test_acc:0.2025790323558911
Starting epoch 3/150.
Epoch finished ! Loss: 0.23089454896174944
train_acc:0.2053063123297784 || test_acc:0.20894466827114797
Starting epoch 4/150.
Epoch finished ! Loss: 0.22622370146788084
train_acc:0.20657407723706084 || test_acc:0.2107487970025317
Starting epoch 5/150.
Epoch finished ! Loss: 0.22501724843795484
train_acc:0.20690080355817184 || test_acc:0.21579573013998304
Starting epoch 6/150.
Epoch finished ! Loss: 0.21965019003703043
train_acc:0.20814103351347243 || test_acc:0.2154207939010001
Starting epoch 7/150.
Epoch finished ! Loss: 0.21719479847412843
train_acc:0.20951749469943734 || test_acc:0.21916807411166722
Starting epoch 8/150.
Epoch finished ! Loss: 0.2151159689976619
train_acc:0.21065634763898827 || test_acc:0.21997231537459835
Starting epoch 9/150.
Epoch finished ! Loss: 0.21353020805578965
train_acc:0.2113040720271388 || test_acc:0.2233338155216191
Starting epoch 10/150.
Epoch finished ! Loss: 0.2126716048671649
train_acc:0.21190537126298975 || test_acc:0.22117041977952828
Starting epoch 11/150.
Epoch finished ! Loss: 0.21059733686538842
train_acc:0.21261360479495464 || test_acc:0.2248599773198107
Starting epoch 12/150.
Epoch finished ! Loss: 0.20883212639735296
train_acc:0.21329410791562062 || test_acc:0.22742912913746113
Starting epoch 13/150.
Epoch finished ! Loss: 0.2062504870387224
train_acc:0.2141435556572701 || test_acc:0.22951345943003468
Starting epoch 14/150.
Epoch finished ! Loss: 0.20518693729088858
train_acc:0.21495328240026584 || test_acc:0.23178456310613252
Starting epoch 15/150.
Epoch finished ! Loss: 0.20313660743144843
train_acc:0.21606639050232035 || test_acc:0.2353199645600489
Starting epoch 16/150.
Epoch finished ! Loss: 0.20339307647485
train_acc:0.21690071764834065 || test_acc:0.23673236678386478
Starting epoch 17/150.
Epoch finished ! Loss: 0.2006256987269108
train_acc:0.21786858185820837 || test_acc:0.24310387793042273
Starting epoch 18/150.
Epoch finished ! Loss: 0.19982916174026635
train_acc:0.21886845371518762 || test_acc:0.23936054785749744
Starting epoch 19/150.
Epoch finished ! Loss: 0.19832312544951072
train_acc:0.2199564548680892 || test_acc:0.24547515156551977
Starting epoch 20/150.
Epoch finished ! Loss: 0.19643605443147513
train_acc:0.22120470343170623 || test_acc:0.2447943221862803
Checkpoint 20 saved !
Starting epoch 21/150.
Epoch finished ! Loss: 0.19667811978321809
train_acc:0.22228978074035313 || test_acc:0.2522409759344168
Starting epoch 22/150.
Epoch finished ! Loss: 0.19496014943489662
train_acc:0.22349732232327027 || test_acc:0.2600558039181333
Starting epoch 23/150.
Epoch finished ! Loss: 0.19486654205964163
train_acc:0.22466904568620805 || test_acc:0.2523423532978784
Starting epoch 24/150.
Epoch finished ! Loss: 0.19370118528604507
train_acc:0.22580350683142156 || test_acc:0.26154114957911356
Starting epoch 25/150.
Epoch finished ! Loss: 0.19228322689349836
train_acc:0.22707653920831108 || test_acc:0.26192996121581896
Starting epoch 26/150.
Epoch finished ! Loss: 0.1928426348246061
train_acc:0.22815298436526094 || test_acc:0.26742805575132744
Starting epoch 27/150.
Epoch finished ! Loss: 0.19176365033938333
train_acc:0.22931783259986177 || test_acc:0.27405607882729666
Starting epoch 28/150.
Epoch finished ! Loss: 0.18972332603656328
train_acc:0.2306791593109658 || test_acc:0.26435527119595625
Starting epoch 29/150.
Epoch finished ! Loss: 0.18984193756030157
train_acc:0.23190417564254276 || test_acc:0.27654953046143876
Starting epoch 30/150.
Epoch finished ! Loss: 0.18900768688091865
train_acc:0.23327264416889534 || test_acc:0.28110934387562947
Starting epoch 31/150.
Epoch finished ! Loss: 0.18744810498677766
train_acc:0.23464434135005138 || test_acc:0.2923623711590756
Starting epoch 32/150.
Epoch finished ! Loss: 0.18778630804557067
train_acc:0.23599888897408972 || test_acc:0.28826139286971125
Starting epoch 33/150.
Epoch finished ! Loss: 0.18560506174197564
train_acc:0.23745411701153096 || test_acc:0.28748079578847363
Starting epoch 34/150.
Epoch finished ! Loss: 0.1864047761146839
train_acc:0.23877734099391712 || test_acc:0.28826774166741237
Starting epoch 35/150.
Epoch finished ! Loss: 0.18528904307347077
train_acc:0.24010991001894735 || test_acc:0.3056980402755328
Starting epoch 36/150.
Epoch finished ! Loss: 0.18478844715998724
train_acc:0.24151537007047408 || test_acc:0.30194996307574373
Starting epoch 37/150.
Epoch finished ! Loss: 0.18291413153593356
train_acc:0.24307977702192063 || test_acc:0.298668624349017
Starting epoch 38/150.
Epoch finished ! Loss: 0.18390994805556077
train_acc:0.2444616659136277 || test_acc:0.3130626860994604
Starting epoch 39/150.
Epoch finished ! Loss: 0.18265126760189349
train_acc:0.2459131682834974 || test_acc:0.30241963339685907
Starting epoch 40/150.
Epoch finished ! Loss: 0.1819463188831623
train_acc:0.24735974273067646 || test_acc:0.3148500403040079
Checkpoint 40 saved !
Starting epoch 41/150.
Epoch finished ! Loss: 0.18214232818438456
train_acc:0.24870587801767688 || test_acc:0.31590405263348686
Starting epoch 42/150.
Epoch finished ! Loss: 0.18268285061304385
train_acc:0.250028953022174 || test_acc:0.31249572177298623
Starting epoch 43/150.
Epoch finished ! Loss: 0.1809330301789137
train_acc:0.2514427255725863 || test_acc:0.31088178106596226
Starting epoch 44/150.
Epoch finished ! Loss: 0.18080286509715593
train_acc:0.2528547613626439 || test_acc:0.3105523027738513
Starting epoch 45/150.
Epoch finished ! Loss: 0.17977612752180833
train_acc:0.2542472643705921 || test_acc:0.3205137535272515
Starting epoch 46/150.
Epoch finished ! Loss: 0.18029775814368174
train_acc:0.25563123809081967 || test_acc:0.32332510004791915
Starting epoch 47/150.
Epoch finished ! Loss: 0.17974664729375106
train_acc:0.25696873271480625 || test_acc:0.3245523652396442
Starting epoch 48/150.
Epoch finished ! Loss: 0.17831892921374395
train_acc:0.25841330706796994 || test_acc:0.33475165331624057
Starting epoch 49/150.
Epoch finished ! Loss: 0.1781890976887483
train_acc:0.2598419242725131 || test_acc:0.32991457586415346
Starting epoch 50/150.
Epoch finished ! Loss: 0.17829690701686418
train_acc:0.26116503634657606 || test_acc:0.3285429935859778
Starting epoch 51/150.
Epoch finished ! Loss: 0.17818390749968016
train_acc:0.2625316329945042 || test_acc:0.3295828807853182
Starting epoch 52/150.
Epoch finished ! Loss: 0.1773653099170098
train_acc:0.2638681364275594 || test_acc:0.3480520327982017
Starting epoch 53/150.
Epoch finished ! Loss: 0.17656105011701584
train_acc:0.2652042723243904 || test_acc:0.33819194549387704
Starting epoch 54/150.
Epoch finished ! Loss: 0.1765579329087184
train_acc:0.2665094645656083 || test_acc:0.3459016739599432
Starting epoch 55/150.
Epoch finished ! Loss: 0.17500764647355446
train_acc:0.26787334615670705 || test_acc:0.3483369485656464
Starting epoch 56/150.
Epoch finished ! Loss: 0.17532312067655417
train_acc:0.2692380042647062 || test_acc:0.34343346456379004
Starting epoch 57/150.
Epoch finished ! Loss: 0.17586035625292704
train_acc:0.2705296553465698 || test_acc:0.3382829448125968
Starting epoch 58/150.
Epoch finished ! Loss: 0.17419356394272584
train_acc:0.2718830930678895 || test_acc:0.3476940292733254
Starting epoch 59/150.
Epoch finished ! Loss: 0.1745944435779865
train_acc:0.27316777850413637 || test_acc:0.3388916438237519
Starting epoch 60/150.
Epoch finished ! Loss: 0.17349878068153674
train_acc:0.2744935257825117 || test_acc:0.3624359484947615
Checkpoint 60 saved !
Starting epoch 61/150.
Epoch finished ! Loss: 0.1744197096962195
train_acc:0.27578194754869717 || test_acc:0.3768019403335443
Starting epoch 62/150.
Epoch finished ! Loss: 0.17295181865875536
train_acc:0.2771095444254536 || test_acc:0.3639677117209444
Starting epoch 63/150.
Epoch finished ! Loss: 0.17245087486047012
train_acc:0.27841636353355415 || test_acc:0.39514576862120043
Starting epoch 64/150.
Epoch finished ! Loss: 0.1731461017177655
train_acc:0.27966671574496166 || test_acc:0.37048311062206457
Starting epoch 65/150.
Epoch finished ! Loss: 0.17213312077980775
train_acc:0.28095753901445536 || test_acc:0.37711790561546255
Starting epoch 66/150.
Epoch finished ! Loss: 0.17198903113603592
train_acc:0.2822165577391584 || test_acc:0.3573437423554302
Starting epoch 67/150.
Epoch finished ! Loss: 0.17203176365448877
train_acc:0.28344381510383 || test_acc:0.38394789800319457
Starting epoch 68/150.
Epoch finished ! Loss: 0.17208514649134415
train_acc:0.2846799619891429 || test_acc:0.38545474901582666
Starting epoch 69/150.
Epoch finished ! Loss: 0.1704947570195565
train_acc:0.28597507293259106 || test_acc:0.372496423529719
Starting epoch 70/150.
Epoch finished ! Loss: 0.16980364345587218
train_acc:0.28731729419230506 || test_acc:0.3774841268935139
Starting epoch 71/150.
Epoch finished ! Loss: 0.1712486296892166
train_acc:0.2885222333246383 || test_acc:0.3768727632290264
Starting epoch 72/150.
Epoch finished ! Loss: 0.16927948078283897
train_acc:0.2898360693607379 || test_acc:0.38545403041196213
Starting epoch 73/150.
Epoch finished ! Loss: 0.17132249417213294
train_acc:0.2909897863661445 || test_acc:0.40391747867093813
Starting epoch 74/150.
Epoch finished ! Loss: 0.16934530608929121
train_acc:0.2922176168540712 || test_acc:0.3857144961548601
Starting epoch 75/150.
Epoch finished ! Loss: 0.16970670968294144
train_acc:0.29341279151656646 || test_acc:0.38032287247269886
Starting epoch 76/150.
Epoch finished ! Loss: 0.16950240960487953
train_acc:0.29459989618127336 || test_acc:0.3950835179838588
Starting epoch 77/150.
Epoch finished ! Loss: 0.16909863226688826
train_acc:0.2958102169700055 || test_acc:0.39422716016506276
Starting epoch 78/150.
Epoch finished ! Loss: 0.1684278049148046
train_acc:0.29703134013042715 || test_acc:0.3894013138698924
Starting epoch 79/150.
Epoch finished ! Loss: 0.1687381353515845
train_acc:0.2981898280838263 || test_acc:0.395588409750994
Starting epoch 80/150.
Epoch finished ! Loss: 0.16926167733394182
train_acc:0.29926754665771294 || test_acc:0.39966967315301216
Checkpoint 80 saved !
Starting epoch 81/150.
Epoch finished ! Loss: 0.1690747095988347
train_acc:0.3003483075864406 || test_acc:0.3946198839488948
Starting epoch 82/150.
Epoch finished ! Loss: 0.1681472510099411
train_acc:0.30150127230863 || test_acc:0.39425597013091496
Starting epoch 83/150.
Epoch finished ! Loss: 0.16753262625290796
train_acc:0.3026503318231734 || test_acc:0.40147327977539343
Starting epoch 84/150.
Epoch finished ! Loss: 0.16764450187866503
train_acc:0.3037472654139794 || test_acc:0.4023196941411469
Starting epoch 85/150.
Epoch finished ! Loss: 0.16711295052216604
train_acc:0.3048733023592111 || test_acc:0.4264768167968316
Starting epoch 86/150.
Epoch finished ! Loss: 0.16658896838243192
train_acc:0.30603042207675135 || test_acc:0.42196131996209113
Starting epoch 87/150.
Epoch finished ! Loss: 0.16779637680603907
train_acc:0.3070647452142458 || test_acc:0.3930357199075487
Starting epoch 88/150.
Epoch finished ! Loss: 0.16705500621062058
train_acc:0.308111726417294 || test_acc:0.41587776605711874
Starting epoch 89/150.
Epoch finished ! Loss: 0.16600663616107061
train_acc:0.30927137184234266 || test_acc:0.4125136936314182
Starting epoch 90/150.
Epoch finished ! Loss: 0.16641366768341798
train_acc:0.31036441045505114 || test_acc:0.4230377404040569
Starting epoch 91/150.
Epoch finished ! Loss: 0.16580722939509612
train_acc:0.3114328988488782 || test_acc:0.42983205766728944
Starting epoch 92/150.
Epoch finished ! Loss: 0.1660379647062375
train_acc:0.3125260398092764 || test_acc:0.4151171191500359
Starting epoch 93/150.
Epoch finished ! Loss: 0.1655236975504802
train_acc:0.31361317990044496 || test_acc:0.4231137975723977
Starting epoch 94/150.
Epoch finished ! Loss: 0.16505058912130502
train_acc:0.3147206089473621 || test_acc:0.41722324192913873
Starting epoch 95/150.
Epoch finished ! Loss: 0.16580391961794633
train_acc:0.3157492149636864 || test_acc:0.4301325876154641
Starting epoch 96/150.
Epoch finished ! Loss: 0.16495574093781984
train_acc:0.316836403496157 || test_acc:0.4308305078604822
Starting epoch 97/150.
Epoch finished ! Loss: 0.16505160010777986
train_acc:0.3178715600681475 || test_acc:0.433137868175151
Starting epoch 98/150.
Epoch finished ! Loss: 0.16449697258380744
train_acc:0.31892444026827244 || test_acc:0.41850669179981226
Starting epoch 99/150.
Epoch finished ! Loss: 0.16464420923819909
train_acc:0.31996830276646854 || test_acc:0.4325886422640356
Starting epoch 100/150.
Epoch finished ! Loss: 0.16521571347346672
train_acc:0.3209531609558669 || test_acc:0.43479078578169567
Checkpoint 100 saved !
Starting epoch 101/150.
Epoch finished ! Loss: 0.16379190522890824
train_acc:0.32200543480945293 || test_acc:0.42912574877061993
Starting epoch 102/150.
Epoch finished ! Loss: 0.16348824478112733
train_acc:0.32307174740902816 || test_acc:0.4405645805419405
Starting epoch 103/150.
Epoch finished ! Loss: 0.1647455904346246
train_acc:0.32402398451008235 || test_acc:0.4227904406406843
Starting epoch 104/150.
Epoch finished ! Loss: 0.16484762556277788
train_acc:0.32496248964987046 || test_acc:0.44676256365907857
Starting epoch 105/150.
Epoch finished ! Loss: 0.16362492740154266
train_acc:0.3259557479768434 || test_acc:0.4260793447920574
Starting epoch 106/150.
Epoch finished ! Loss: 0.16419120877981186
train_acc:0.32689345913190393 || test_acc:0.45393212045355774
Starting epoch 107/150.
Epoch finished ! Loss: 0.16454196262818116
train_acc:0.3278128039015093 || test_acc:0.4476054686160187
Starting epoch 108/150.
Epoch finished ! Loss: 0.16359196259425238
train_acc:0.32874391773236267 || test_acc:0.43762765421005095
Starting epoch 109/150.
Epoch finished ! Loss: 0.1635544844544851
train_acc:0.3296889927674964 || test_acc:0.4688277828211342
Starting epoch 110/150.
Epoch finished ! Loss: 0.16314512892411306
train_acc:0.330637793762175 || test_acc:0.4370008552309965
Starting epoch 111/150.
Epoch finished ! Loss: 0.163160180243162
train_acc:0.33156835767685616 || test_acc:0.439336924159203
Starting epoch 112/150.
Epoch finished ! Loss: 0.16286184753362948
train_acc:0.3325088639127069 || test_acc:0.452101014855467
Starting epoch 113/150.
Epoch finished ! Loss: 0.16226295611033073
train_acc:0.33345293399957593 || test_acc:0.4571180672706455
Starting epoch 114/150.
Epoch finished ! Loss: 0.16183032095432281
train_acc:0.33444406078448863 || test_acc:0.4515290201181882
Starting epoch 115/150.
Epoch finished ! Loss: 0.16224844065996316
train_acc:0.3353424828185532 || test_acc:0.4375065842832045
Starting epoch 116/150.
Epoch finished ! Loss: 0.16149563972766584
train_acc:0.3363125730021047 || test_acc:0.4366381496787042
Starting epoch 117/150.
Epoch finished ! Loss: 0.1619265194122608
train_acc:0.33722331464298744 || test_acc:0.44810519444300556
Starting epoch 118/150.
Epoch finished ! Loss: 0.16141476596777254
train_acc:0.338183832884983 || test_acc:0.4467645974661786
Starting epoch 119/150.
Epoch finished ! Loss: 0.16194211863554442
train_acc:0.3390890774944391 || test_acc:0.44855992642518816
Starting epoch 120/150.
Epoch finished ! Loss: 0.16137082416277665
train_acc:0.34000524672369115 || test_acc:0.4510537116888362
Checkpoint 120 saved !
Starting epoch 121/150.
Epoch finished ! Loss: 0.1610308765218808
train_acc:0.3409526048432968 || test_acc:0.4561990299398795
Starting epoch 122/150.
Epoch finished ! Loss: 0.16164265802273384
train_acc:0.3418126993461251 || test_acc:0.4695217197094236
Starting epoch 123/150.
Epoch finished ! Loss: 0.16116226808382914
train_acc:0.342710155872649 || test_acc:0.4516272041774815
Starting epoch 124/150.
Epoch finished ! Loss: 0.16128855083997434
train_acc:0.3435943133943987 || test_acc:0.45242225787474305
Starting epoch 125/150.
Epoch finished ! Loss: 0.16091109869571832
train_acc:0.3444919137613651 || test_acc:0.4589889513529777
Starting epoch 126/150.
Epoch finished ! Loss: 0.16224641295579764
train_acc:0.34530503326222467 || test_acc:0.4669593701724595
Starting epoch 127/150.
Epoch finished ! Loss: 0.16095131578353736
train_acc:0.3461247073781741 || test_acc:0.4661914493992149
Starting epoch 128/150.
Epoch finished ! Loss: 0.16120758767311388
train_acc:0.34693116310841543 || test_acc:0.46443612995098477
Starting epoch 129/150.
Epoch finished ! Loss: 0.1607873267852343
train_acc:0.3477526264358121 || test_acc:0.4703874000052568
Starting epoch 130/150.
Epoch finished ! Loss: 0.1607287130676783
train_acc:0.3485970418559025 || test_acc:0.4686838100906003
Starting epoch 131/150.
Epoch finished ! Loss: 0.16055029172163743
train_acc:0.34943026373713393 || test_acc:0.4704980779823475
Starting epoch 132/150.
Epoch finished ! Loss: 0.1604906257528525
train_acc:0.3502381124763342 || test_acc:0.46308080364392523
Starting epoch 133/150.
Epoch finished ! Loss: 0.1598400238614816
train_acc:0.3511118199583562 || test_acc:0.4616002159638877
Starting epoch 134/150.
Epoch finished ! Loss: 0.1595925402182799
train_acc:0.35198669576195374 || test_acc:0.47625659438774093
Starting epoch 135/150.
Epoch finished ! Loss: 0.1602242417060412
train_acc:0.35277587212608774 || test_acc:0.46337520243583846
Starting epoch 136/150.
Epoch finished ! Loss: 0.16103059339981812
train_acc:0.3535497735007315 || test_acc:0.47692552393070337
Starting epoch 137/150.
Epoch finished ! Loss: 0.1605008766055107
train_acc:0.35430879022371603 || test_acc:0.4812065226185204
Starting epoch 138/150.
Epoch finished ! Loss: 0.15971070298781762
train_acc:0.35512907537769833 || test_acc:0.4870415616827695
Starting epoch 139/150.
Epoch finished ! Loss: 0.1599417535158304
train_acc:0.3559365966656561 || test_acc:0.46635861834869846
Starting epoch 140/150.
Epoch finished ! Loss: 0.1594546729555497
train_acc:0.3567343612976816 || test_acc:0.4837476167083612
Checkpoint 140 saved !
Starting epoch 141/150.
Epoch finished ! Loss: 0.15989388353549516
train_acc:0.35753342054856496 || test_acc:0.47758389795118467
Starting epoch 142/150.
Epoch finished ! Loss: 0.15925977722956583
train_acc:0.35833995706100125 || test_acc:0.48039827095815
Starting epoch 143/150.
Epoch finished ! Loss: 0.15955477437147728
train_acc:0.3591219981320733 || test_acc:0.4834341525913093
Starting epoch 144/150.
Epoch finished ! Loss: 0.15969339242348304
train_acc:0.3598885163819935 || test_acc:0.4754819946139139
Starting epoch 145/150.
Epoch finished ! Loss: 0.1592084261087271
train_acc:0.360652374747902 || test_acc:0.49259145777270136
Starting epoch 146/150.
Epoch finished ! Loss: 0.15897265592446694
train_acc:0.36145560732817467 || test_acc:0.49345523034755984
Starting epoch 147/150.
Epoch finished ! Loss: 0.15914421872450754
train_acc:0.3622245056066309 || test_acc:0.477809695829005
Starting epoch 148/150.
Epoch finished ! Loss: 0.15909265956053367
train_acc:0.362988383732368 || test_acc:0.48802890351518213
Starting epoch 149/150.
Epoch finished ! Loss: 0.15868968401963895
train_acc:0.363757002218453 || test_acc:0.4787174281747036
Starting epoch 150/150.
Epoch finished ! Loss: 0.15916903374286798
train_acc:0.3645001903789981 || test_acc:0.49554947665099397
END epoch150!
输出train每个epoch的loss值:
train_loss_epoch:[0.23831874705277956, 0.2328639695277581, 0.23089454896174944, 0.22622370146788084, 0.22501724843795484, 0.21965019003703043, 0.21719479847412843, 0.2151159689976619, 0.21353020805578965, 0.2126716048671649, 0.21059733686538842, 0.20883212639735296, 0.2062504870387224, 0.20518693729088858, 0.20313660743144843, 0.20339307647485, 0.2006256987269108, 0.19982916174026635, 0.19832312544951072, 0.19643605443147513, 0.19667811978321809, 0.19496014943489662, 0.19486654205964163, 0.19370118528604507, 0.19228322689349836, 0.1928426348246061, 0.19176365033938333, 0.18972332603656328, 0.18984193756030157, 0.18900768688091865, 0.18744810498677766, 0.18778630804557067, 0.18560506174197564, 0.1864047761146839, 0.18528904307347077, 0.18478844715998724, 0.18291413153593356, 0.18390994805556077, 0.18265126760189349, 0.1819463188831623, 0.18214232818438456, 0.18268285061304385, 0.1809330301789137, 0.18080286509715593, 0.17977612752180833, 0.18029775814368174, 0.17974664729375106, 0.17831892921374395, 0.1781890976887483, 0.17829690701686418, 0.17818390749968016, 0.1773653099170098, 0.17656105011701584, 0.1765579329087184, 0.17500764647355446, 0.17532312067655417, 0.17586035625292704, 0.17419356394272584, 0.1745944435779865, 0.17349878068153674, 0.1744197096962195, 0.17295181865875536, 0.17245087486047012, 0.1731461017177655, 0.17213312077980775, 0.17198903113603592, 0.17203176365448877, 0.17208514649134415, 0.1704947570195565, 0.16980364345587218, 0.1712486296892166, 0.16927948078283897, 0.17132249417213294, 0.16934530608929121, 0.16970670968294144, 0.16950240960487953, 0.16909863226688826, 0.1684278049148046, 0.1687381353515845, 0.16926167733394182, 0.1690747095988347, 0.1681472510099411, 0.16753262625290796, 0.16764450187866503, 0.16711295052216604, 0.16658896838243192, 0.16779637680603907, 0.16705500621062058, 0.16600663616107061, 0.16641366768341798, 0.16580722939509612, 0.1660379647062375, 0.1655236975504802, 0.16505058912130502, 0.16580391961794633, 0.16495574093781984, 0.16505160010777986, 0.16449697258380744, 0.16464420923819909, 0.16521571347346672, 0.16379190522890824, 0.16348824478112733, 0.1647455904346246, 0.16484762556277788, 0.16362492740154266, 0.16419120877981186, 0.16454196262818116, 0.16359196259425238, 0.1635544844544851, 0.16314512892411306, 0.163160180243162, 0.16286184753362948, 0.16226295611033073, 0.16183032095432281, 0.16224844065996316, 0.16149563972766584, 0.1619265194122608, 0.16141476596777254, 0.16194211863554442, 0.16137082416277665, 0.1610308765218808, 0.16164265802273384, 0.16116226808382914, 0.16128855083997434, 0.16091109869571832, 0.16224641295579764, 0.16095131578353736, 0.16120758767311388, 0.1607873267852343, 0.1607287130676783, 0.16055029172163743, 0.1604906257528525, 0.1598400238614816, 0.1595925402182799, 0.1602242417060412, 0.16103059339981812, 0.1605008766055107, 0.15971070298781762, 0.1599417535158304, 0.1594546729555497, 0.15989388353549516, 0.15925977722956583, 0.15955477437147728, 0.15969339242348304, 0.1592084261087271, 0.15897265592446694, 0.15914421872450754, 0.15909265956053367, 0.15868968401963895, 0.15916903374286798]
输出valid每个epoch的loss值:
valid_loss_epoch:[]
输出每个epoch的acc值:
train_acc_epoch:[0.20354749720140364, 0.20495814876798152, 0.2053063123297784, 0.20657407723706084, 0.20690080355817184, 0.20814103351347243, 0.20951749469943734, 0.21065634763898827, 0.2113040720271388, 0.21190537126298975, 0.21261360479495464, 0.21329410791562062, 0.2141435556572701, 0.21495328240026584, 0.21606639050232035, 0.21690071764834065, 0.21786858185820837, 0.21886845371518762, 0.2199564548680892, 0.22120470343170623, 0.22228978074035313, 0.22349732232327027, 0.22466904568620805, 0.22580350683142156, 0.22707653920831108, 0.22815298436526094, 0.22931783259986177, 0.2306791593109658, 0.23190417564254276, 0.23327264416889534, 0.23464434135005138, 0.23599888897408972, 0.23745411701153096, 0.23877734099391712, 0.24010991001894735, 0.24151537007047408, 0.24307977702192063, 0.2444616659136277, 0.2459131682834974, 0.24735974273067646, 0.24870587801767688, 0.250028953022174, 0.2514427255725863, 0.2528547613626439, 0.2542472643705921, 0.25563123809081967, 0.25696873271480625, 0.25841330706796994, 0.2598419242725131, 0.26116503634657606, 0.2625316329945042, 0.2638681364275594, 0.2652042723243904, 0.2665094645656083, 0.26787334615670705, 0.2692380042647062, 0.2705296553465698, 0.2718830930678895, 0.27316777850413637, 0.2744935257825117, 0.27578194754869717, 0.2771095444254536, 0.27841636353355415, 0.27966671574496166, 0.28095753901445536, 0.2822165577391584, 0.28344381510383, 0.2846799619891429, 0.28597507293259106, 0.28731729419230506, 0.2885222333246383, 0.2898360693607379, 0.2909897863661445, 0.2922176168540712, 0.29341279151656646, 0.29459989618127336, 0.2958102169700055, 0.29703134013042715, 0.2981898280838263, 0.29926754665771294, 0.3003483075864406, 0.30150127230863, 0.3026503318231734, 0.3037472654139794, 0.3048733023592111, 0.30603042207675135, 0.3070647452142458, 0.308111726417294, 0.30927137184234266, 0.31036441045505114, 0.3114328988488782, 0.3125260398092764, 0.31361317990044496, 0.3147206089473621, 0.3157492149636864, 0.316836403496157, 0.3178715600681475, 0.31892444026827244, 0.31996830276646854, 0.3209531609558669, 0.32200543480945293, 0.32307174740902816, 0.32402398451008235, 0.32496248964987046, 0.3259557479768434, 0.32689345913190393, 0.3278128039015093, 0.32874391773236267, 0.3296889927674964, 0.330637793762175, 0.33156835767685616, 0.3325088639127069, 0.33345293399957593, 0.33444406078448863, 0.3353424828185532, 0.3363125730021047, 0.33722331464298744, 0.338183832884983, 0.3390890774944391, 0.34000524672369115, 0.3409526048432968, 0.3418126993461251, 0.342710155872649, 0.3435943133943987, 0.3444919137613651, 0.34530503326222467, 0.3461247073781741, 0.34693116310841543, 0.3477526264358121, 0.3485970418559025, 0.34943026373713393, 0.3502381124763342, 0.3511118199583562, 0.35198669576195374, 0.35277587212608774, 0.3535497735007315, 0.35430879022371603, 0.35512907537769833, 0.3559365966656561, 0.3567343612976816, 0.35753342054856496, 0.35833995706100125, 0.3591219981320733, 0.3598885163819935, 0.360652374747902, 0.36145560732817467, 0.3622245056066309, 0.362988383732368, 0.363757002218453, 0.3645001903789981]
 valid_acc_epoch:[0.20645750584272882, 0.2025790323558911, 0.20894466827114797, 0.2107487970025317, 0.21579573013998304, 0.2154207939010001, 0.21916807411166722, 0.21997231537459835, 0.2233338155216191, 0.22117041977952828, 0.2248599773198107, 0.22742912913746113, 0.22951345943003468, 0.23178456310613252, 0.2353199645600489, 0.23673236678386478, 0.24310387793042273, 0.23936054785749744, 0.24547515156551977, 0.2447943221862803, 0.2522409759344168, 0.2600558039181333, 0.2523423532978784, 0.26154114957911356, 0.26192996121581896, 0.26742805575132744, 0.27405607882729666, 0.26435527119595625, 0.27654953046143876, 0.28110934387562947, 0.2923623711590756, 0.28826139286971125, 0.28748079578847363, 0.28826774166741237, 0.3056980402755328, 0.30194996307574373, 0.298668624349017, 0.3130626860994604, 0.30241963339685907, 0.3148500403040079, 0.31590405263348686, 0.31249572177298623, 0.31088178106596226, 0.3105523027738513, 0.3205137535272515, 0.32332510004791915, 0.3245523652396442, 0.33475165331624057, 0.32991457586415346, 0.3285429935859778, 0.3295828807853182, 0.3480520327982017, 0.33819194549387704, 0.3459016739599432, 0.3483369485656464, 0.34343346456379004, 0.3382829448125968, 0.3476940292733254, 0.3388916438237519, 0.3624359484947615, 0.3768019403335443, 0.3639677117209444, 0.39514576862120043, 0.37048311062206457, 0.37711790561546255, 0.3573437423554302, 0.38394789800319457, 0.38545474901582666, 0.372496423529719, 0.3774841268935139, 0.3768727632290264, 0.38545403041196213, 0.40391747867093813, 0.3857144961548601, 0.38032287247269886, 0.3950835179838588, 0.39422716016506276, 0.3894013138698924, 0.395588409750994, 0.39966967315301216, 0.3946198839488948, 0.39425597013091496, 0.40147327977539343, 0.4023196941411469, 0.4264768167968316, 0.42196131996209113, 0.3930357199075487, 0.41587776605711874, 0.4125136936314182, 0.4230377404040569, 0.42983205766728944, 0.4151171191500359, 0.4231137975723977, 0.41722324192913873, 0.4301325876154641, 0.4308305078604822, 0.433137868175151, 0.41850669179981226, 0.4325886422640356, 0.43479078578169567, 0.42912574877061993, 0.4405645805419405, 0.4227904406406843, 0.44676256365907857, 0.4260793447920574, 0.45393212045355774, 0.4476054686160187, 0.43762765421005095, 0.4688277828211342, 0.4370008552309965, 0.439336924159203, 0.452101014855467, 0.4571180672706455, 0.4515290201181882, 0.4375065842832045, 0.4366381496787042, 0.44810519444300556, 0.4467645974661786, 0.44855992642518816, 0.4510537116888362, 0.4561990299398795, 0.4695217197094236, 0.4516272041774815, 0.45242225787474305, 0.4589889513529777, 0.4669593701724595, 0.4661914493992149, 0.46443612995098477, 0.4703874000052568, 0.4686838100906003, 0.4704980779823475, 0.46308080364392523, 0.4616002159638877, 0.47625659438774093, 0.46337520243583846, 0.47692552393070337, 0.4812065226185204, 0.4870415616827695, 0.46635861834869846, 0.4837476167083612, 0.47758389795118467, 0.48039827095815, 0.4834341525913093, 0.4754819946139139, 0.49259145777270136, 0.49345523034755984, 0.477809695829005, 0.48802890351518213, 0.4787174281747036, 0.49554947665099397]
输出最后一个epoch的值:
train_acc:0.3645001903789981 | valid_acc:0.49554947665099397

Starting epoch 1/150.
/home/huangjq/anaconda3/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Epoch finished ! Loss: 0.2074345275759697
train_acc:0.27932615060254284 || test_acc:0.22016097136108517
Starting epoch 2/150.
Epoch finished ! Loss: 0.203783090871114
train_acc:0.28322156554184547 || test_acc:0.2664572819123179
Starting epoch 3/150.
Epoch finished ! Loss: 0.2026076792524411
train_acc:0.2847435427078784 || test_acc:0.3014981200863307
Starting epoch 4/150.
Epoch finished ! Loss: 0.2025472389963957
train_acc:0.28599866092419934 || test_acc:0.3087550482579793
Starting epoch 5/150.
Epoch finished ! Loss: 0.20047383870069796
train_acc:0.28779029703033693 || test_acc:0.30390184242654034
Starting epoch 6/150.
Epoch finished ! Loss: 0.1977322227679766
train_acc:0.2896429613458858 || test_acc:0.2977230930747212
Starting epoch 7/150.
Epoch finished ! Loss: 0.1970054661998382
train_acc:0.29114389815849145 || test_acc:0.3100211929248867
Starting epoch 8/150.
Epoch finished ! Loss: 0.19661698031883973
train_acc:0.2930045299020127 || test_acc:0.31496600558611154
Starting epoch 9/150.
Epoch finished ! Loss: 0.1964181546981518
train_acc:0.29432114089026573 || test_acc:0.32954550483777967
Starting epoch 10/150.
Epoch finished ! Loss: 0.19435437195576155
train_acc:0.2959916340154794 || test_acc:0.3211341050361573
Starting epoch 11/150.
Epoch finished ! Loss: 0.1939917287001243
train_acc:0.2972975795456319 || test_acc:0.3206737163897404
Starting epoch 12/150.
Epoch finished ! Loss: 0.1925974379365261
train_acc:0.2987222846769939 || test_acc:0.33183284195797297
Starting epoch 13/150.
Epoch finished ! Loss: 0.19200260020219362
train_acc:0.3000171977721563 || test_acc:0.33388445831823976
Starting epoch 14/150.
Epoch finished ! Loss: 0.19212372314471465
train_acc:0.3012301797853854 || test_acc:0.33698239825154114
Starting epoch 15/150.
Epoch finished ! Loss: 0.19174265001828855
train_acc:0.3021397365691976 || test_acc:0.3275563337923393
Starting epoch 16/150.
Epoch finished ! Loss: 0.19142395143325514
train_acc:0.3031575925148819 || test_acc:0.33428280268564725
Starting epoch 17/150.
Epoch finished ! Loss: 0.19047389466028947
train_acc:0.304135089845711 || test_acc:0.3344568678626166
Starting epoch 18/150.
Epoch finished ! Loss: 0.18896214893231025
train_acc:0.30515838772591175 || test_acc:0.3431683594319114
Starting epoch 19/150.
Epoch finished ! Loss: 0.1887347801373555
train_acc:0.306125736823487 || test_acc:0.34184589515420205
Starting epoch 20/150.
Epoch finished ! Loss: 0.1870169032078523
train_acc:0.30721168620801376 || test_acc:0.34229760643797713
Checkpoint 20 saved !
Starting epoch 21/150.
Epoch finished ! Loss: 0.18786631524562836
train_acc:0.308222862400972 || test_acc:0.34410414498984043
Starting epoch 22/150.
Epoch finished ! Loss: 0.187588896888953
train_acc:0.30905121912973876 || test_acc:0.3430636151310396
Starting epoch 23/150.
Epoch finished ! Loss: 0.18635375568499932
train_acc:0.31002625500361836 || test_acc:0.34713879002003106
Starting epoch 24/150.
Epoch finished ! Loss: 0.18618835107638285
train_acc:0.31081050617889827 || test_acc:0.3465399835833611
Starting epoch 25/150.
Epoch finished ! Loss: 0.18639839841769293
train_acc:0.31162119088225176 || test_acc:0.34878448429052994
Starting epoch 26/150.
Epoch finished ! Loss: 0.18381958168286544
train_acc:0.3127323124842886 || test_acc:0.3486631299148875
Starting epoch 27/150.
Epoch finished ! Loss: 0.18494352812950426
train_acc:0.31359860240467835 || test_acc:0.34804859015908957
Starting epoch 28/150.
Epoch finished ! Loss: 0.18366867762345535
train_acc:0.3146505473297833 || test_acc:0.3544565673237951
Starting epoch 29/150.
Epoch finished ! Loss: 0.18428126321389124
train_acc:0.3154585743141472 || test_acc:0.3554636845742411
Starting epoch 30/150.
Epoch finished ! Loss: 0.18260004486028963
train_acc:0.3164458813990067 || test_acc:0.3554431312969182
Starting epoch 31/150.
Epoch finished ! Loss: 0.18279790190549997
train_acc:0.3173884295331177 || test_acc:0.3636319789013291
Starting epoch 32/150.
Epoch finished ! Loss: 0.1811412165944393
train_acc:0.31841838782934573 || test_acc:0.3575259313443966
Starting epoch 33/150.
Epoch finished ! Loss: 0.18141789791675714
train_acc:0.31926383048617885 || test_acc:0.36255515658545545
Starting epoch 34/150.
Epoch finished ! Loss: 0.18091642226164156
train_acc:0.32020418848659865 || test_acc:0.3736649736191552
Starting epoch 35/150.
Epoch finished ! Loss: 0.18165300901119524
train_acc:0.32096497201618795 || test_acc:0.3675872930965306
Starting epoch 36/150.
Epoch finished ! Loss: 0.18066422641277313
train_acc:0.3217863524831262 || test_acc:0.3679167112739744
Starting epoch 37/150.
Epoch finished ! Loss: 0.17884734846078432
train_acc:0.3228110080240505 || test_acc:0.38139219196510576
Starting epoch 38/150.
Epoch finished ! Loss: 0.17863834420075783
train_acc:0.3237173525118794 || test_acc:0.3666776258773829
Starting epoch 39/150.
Epoch finished ! Loss: 0.18020003804793724
train_acc:0.32448770111354674 || test_acc:0.3690292734281549
Starting epoch 40/150.
Epoch finished ! Loss: 0.1796482916061695
train_acc:0.3253065845090883 || test_acc:0.37521971694779116
Checkpoint 40 saved !
Starting epoch 41/150.
Epoch finished ! Loss: 0.17811396087591463
train_acc:0.32619792131193764 || test_acc:0.3800576689987439
Starting epoch 42/150.
Epoch finished ! Loss: 0.1771496287905253
train_acc:0.32713301203974005 || test_acc:0.38284499207544453
Starting epoch 43/150.
Epoch finished ! Loss: 0.17697928043512198
train_acc:0.3279785860210416 || test_acc:0.38511094878399654
Starting epoch 44/150.
Epoch finished ! Loss: 0.1771257330591862
train_acc:0.32883578527862195 || test_acc:0.3711157771494361
Starting epoch 45/150.
Epoch finished ! Loss: 0.17650844156742096
train_acc:0.3297259272073704 || test_acc:0.3764218197727322
Starting epoch 46/150.
Epoch finished ! Loss: 0.1756649951522167
train_acc:0.33064200893507517 || test_acc:0.3759627537970887
Starting epoch 47/150.
Epoch finished ! Loss: 0.17627815157175064
train_acc:0.3315486472337272 || test_acc:0.3828297589835934
Starting epoch 48/150.
Epoch finished ! Loss: 0.1759491150195782
train_acc:0.3324265965632971 || test_acc:0.39234720056833394
Starting epoch 49/150.
Epoch finished ! Loss: 0.17481975372021014
train_acc:0.33330628668586265 || test_acc:0.385319507311505
Starting epoch 50/150.
Epoch finished ! Loss: 0.17545822262763977
train_acc:0.3341319598583846 || test_acc:0.386918132157358
Starting epoch 51/150.
Epoch finished ! Loss: 0.17446641394725212
train_acc:0.33501628363616587 || test_acc:0.38748109921124363
Starting epoch 52/150.
Epoch finished ! Loss: 0.17460241054113096
train_acc:0.3358669907956203 || test_acc:0.38714677576923073
Starting epoch 53/150.
Epoch finished ! Loss: 0.1742741001340059
train_acc:0.3366972858488509 || test_acc:0.39928289850364823
Starting epoch 54/150.
Epoch finished ! Loss: 0.17458168933024773
train_acc:0.33746590678955596 || test_acc:0.38940286925424933
Starting epoch 55/150.
Epoch finished ! Loss: 0.17452813513003862
train_acc:0.3382478132730009 || test_acc:0.39357584987115346
Starting epoch 56/150.
Epoch finished ! Loss: 0.1735126060935167
train_acc:0.33906540846055283 || test_acc:0.3968603293263598
Starting epoch 57/150.
Epoch finished ! Loss: 0.17314503571161857
train_acc:0.33991043867951604 || test_acc:0.40029089517180744
Starting epoch 58/150.
Epoch finished ! Loss: 0.17264044571381348
train_acc:0.3407557914505193 || test_acc:0.39808723061890516
Starting epoch 59/150.
Epoch finished ! Loss: 0.17217522859573364
train_acc:0.34157262344245315 || test_acc:0.4033498149213054
Starting epoch 60/150.
Epoch finished ! Loss: 0.17174811088121855
train_acc:0.3423951892922143 || test_acc:0.39075237186694706
Checkpoint 60 saved !
Starting epoch 61/150.
Epoch finished ! Loss: 0.17218253245720497
train_acc:0.3432178016432514 || test_acc:0.39717238697319124
Starting epoch 62/150.
Epoch finished ! Loss: 0.1715489047077986
train_acc:0.3440275414786207 || test_acc:0.4059591511449911
Starting epoch 63/150.
Epoch finished ! Loss: 0.1716001285956456
train_acc:0.34486324848726413 || test_acc:0.40579160793489216
Starting epoch 64/150.
Epoch finished ! Loss: 0.17030182767372865
train_acc:0.3456831586642441 || test_acc:0.4074896232844831
Starting epoch 65/150.
Epoch finished ! Loss: 0.17137263657955024
train_acc:0.34645941526109075 || test_acc:0.40178730510053623
Starting epoch 66/150.
Epoch finished ! Loss: 0.17106568068265915
train_acc:0.34723835073069415 || test_acc:0.4096228625200907
Starting epoch 67/150.
Epoch finished ! Loss: 0.1709535620533503
train_acc:0.34796298757641764 || test_acc:0.41532751972597953
Starting epoch 68/150.
Epoch finished ! Loss: 0.17035519159757173
train_acc:0.34875086049815 || test_acc:0.41674317311361414
Starting epoch 69/150.
Epoch finished ! Loss: 0.17079662932799414
train_acc:0.3494766191350062 || test_acc:0.4251439981769521
Starting epoch 70/150.
Epoch finished ! Loss: 0.1708808455329675
train_acc:0.35020429092176353 || test_acc:0.40912535858340393
Starting epoch 71/150.
Epoch finished ! Loss: 0.16889753307287508
train_acc:0.35098199792044776 || test_acc:0.4212080469813079
Starting epoch 72/150.
Epoch finished ! Loss: 0.1699183279505143
train_acc:0.35168558103858644 || test_acc:0.4169954706752583
Starting epoch 73/150.
Epoch finished ! Loss: 0.16949588805437088
train_acc:0.352419529478127 || test_acc:0.4277290122129148
Starting epoch 74/150.
Epoch finished ! Loss: 0.16856955794187692
train_acc:0.3531767882415493 || test_acc:0.43172872941593277
Starting epoch 75/150.
Epoch finished ! Loss: 0.16824483642211327
train_acc:0.35392951987432436 || test_acc:0.41835962188411147
Starting epoch 76/150.
Epoch finished ! Loss: 0.16807550134567115
train_acc:0.3546913931510804 || test_acc:0.42854190713364315
Starting epoch 77/150.
Epoch finished ! Loss: 0.1678203115096459
train_acc:0.3554026622856409 || test_acc:0.4219999308730986
Starting epoch 78/150.
Epoch finished ! Loss: 0.16786071199637193
train_acc:0.3561005036685311 || test_acc:0.42741354185533326
Starting epoch 79/150.
Epoch finished ! Loss: 0.16752755011503512
train_acc:0.35685478151773387 || test_acc:0.42744737806820976
Starting epoch 80/150.
Epoch finished ! Loss: 0.16796720601045168
train_acc:0.35754066814441077 || test_acc:0.4247933513686604
Checkpoint 80 saved !
Starting epoch 81/150.
Epoch finished ! Loss: 0.1671036034822464
train_acc:0.3582489649897671 || test_acc:0.41899622830480227
Starting epoch 82/150.
Epoch finished ! Loss: 0.16763707594229624
train_acc:0.3589165649428054 || test_acc:0.4215930295380669
Starting epoch 83/150.
Epoch finished ! Loss: 0.16769311290520889
train_acc:0.3596029482207766 || test_acc:0.4351882042923465
Starting epoch 84/150.
Epoch finished ! Loss: 0.16759448785048264
train_acc:0.3602751133692171 || test_acc:0.4455111513927036
Starting epoch 85/150.
Epoch finished ! Loss: 0.1666405378625943
train_acc:0.36097614649024545 || test_acc:0.434697656128672
Starting epoch 86/150.
Epoch finished ! Loss: 0.16542339496887648
train_acc:0.36172515303545516 || test_acc:0.4363591657898555
Starting epoch 87/150.
Epoch finished ! Loss: 0.16568294339455092
train_acc:0.36244689886614423 || test_acc:0.4307339681840226
Starting epoch 88/150.
Epoch finished ! Loss: 0.16538682064184776
train_acc:0.3631873318350077 || test_acc:0.44569945792265353
Starting epoch 89/150.
Epoch finished ! Loss: 0.16577360950983488
train_acc:0.3638652418685668 || test_acc:0.4349989811147131
Starting epoch 90/150.
Epoch finished ! Loss: 0.16548373836737412
train_acc:0.36452519976296177 || test_acc:0.45097397832246666
Starting epoch 91/150.
Epoch finished ! Loss: 0.16550892018354857
train_acc:0.36517702796304596 || test_acc:0.44394349622832313
Starting epoch 92/150.
Epoch finished ! Loss: 0.16548403925620592
train_acc:0.3658181434761394 || test_acc:0.4420868190511669
Starting epoch 93/150.
Epoch finished ! Loss: 0.16575021296739578
train_acc:0.3664318513806177 || test_acc:0.4480442727332061
Starting epoch 94/150.
Epoch finished ! Loss: 0.16504108160734177
train_acc:0.3671188404062498 || test_acc:0.4386854684424956
Starting epoch 95/150.
Epoch finished ! Loss: 0.16463265281457168
train_acc:0.3677786916240404 || test_acc:0.44787592208943966
Starting epoch 96/150.
Epoch finished ! Loss: 0.16373901355725068
train_acc:0.36849060960874674 || test_acc:0.44467418706863154
Starting epoch 97/150.
Epoch finished ! Loss: 0.16535839896935683
train_acc:0.36907320719785036 || test_acc:0.4513445862995291
Starting epoch 98/150.
Epoch finished ! Loss: 0.16445170113673577
train_acc:0.3697321507982301 || test_acc:0.45129901474120276
Starting epoch 99/150.
Epoch finished ! Loss: 0.16331819731455582
train_acc:0.37044615762401634 || test_acc:0.4494853402191799
Starting epoch 100/150.
Epoch finished ! Loss: 0.16466056326260933
train_acc:0.3710374962738257 || test_acc:0.4427695632105743
Checkpoint 100 saved !
Starting epoch 101/150.
Epoch finished ! Loss: 0.16396599721450072
train_acc:0.37164427202787004 || test_acc:0.44890476301638904
Starting epoch 102/150.
Epoch finished ! Loss: 0.16394345920819503
train_acc:0.3722718655153018 || test_acc:0.4458656645092035
Starting epoch 103/150.
Epoch finished ! Loss: 0.16370916767762259
train_acc:0.3728758665843605 || test_acc:0.45689465785979705
Starting epoch 104/150.
Epoch finished ! Loss: 0.16320963031970537
train_acc:0.37353719932590873 || test_acc:0.4560876753990771
Starting epoch 105/150.
Epoch finished ! Loss: 0.16312695351930764
train_acc:0.37415429612166295 || test_acc:0.45092831188033483
Starting epoch 106/150.
Epoch finished ! Loss: 0.16330577089236334
train_acc:0.37476048256914357 || test_acc:0.4556504093619856
Starting epoch 107/150.
Epoch finished ! Loss: 0.16327481946119896
train_acc:0.3753612842831394 || test_acc:0.45262368266719705
Starting epoch 108/150.
Epoch finished ! Loss: 0.16224866589674583
train_acc:0.3759951412698322 || test_acc:0.4666368068218302
Starting epoch 109/150.
Epoch finished ! Loss: 0.1620090426160739
train_acc:0.3766613906826468 || test_acc:0.4619935099886937
Starting epoch 110/150.
Epoch finished ! Loss: 0.1627259082519091
train_acc:0.37723865374639975 || test_acc:0.45850809549180527
Starting epoch 111/150.
Epoch finished ! Loss: 0.1618829323695256
train_acc:0.37787170517641344 || test_acc:0.45942352301473904
Starting epoch 112/150.
Epoch finished ! Loss: 0.16170804374493086
train_acc:0.37849957061903033 || test_acc:0.46174741485484294
Starting epoch 113/150.
Epoch finished ! Loss: 0.16192437192568412
train_acc:0.3790912177318055 || test_acc:0.46664758229983505
Starting epoch 114/150.
Epoch finished ! Loss: 0.16206459414500457
train_acc:0.3796617941710696 || test_acc:0.4718868161484035
Starting epoch 115/150.
Epoch finished ! Loss: 0.16185758205560538
train_acc:0.3802049912173493 || test_acc:0.46415707897373537
Starting epoch 116/150.
Epoch finished ! Loss: 0.1609237348804107
train_acc:0.3808241242573479 || test_acc:0.45323869723179866
Starting epoch 117/150.
Epoch finished ! Loss: 0.1612696309502308
train_acc:0.38140221306015226 || test_acc:0.469845467051867
Starting epoch 118/150.
Epoch finished ! Loss: 0.16052521020174026
train_acc:0.38201006313536967 || test_acc:0.47237455950076784
Starting epoch 119/150.
Epoch finished ! Loss: 0.16063228536110657
train_acc:0.38262807463332904 || test_acc:0.4808123240625379
Starting epoch 120/150.
Epoch finished ! Loss: 0.16049166195667708
train_acc:0.3832368054018088 || test_acc:0.46540603379086387
Checkpoint 120 saved !
Starting epoch 121/150.
Epoch finished ! Loss: 0.1610720192010586
train_acc:0.38378256343305495 || test_acc:0.4676083038610468
Starting epoch 122/150.
Epoch finished ! Loss: 0.16068983192627245
train_acc:0.38436049602256117 || test_acc:0.4808405593601088
Starting epoch 123/150.
Epoch finished ! Loss: 0.1615198655770375
train_acc:0.3848905619867847 || test_acc:0.4776769093737709
Starting epoch 124/150.
Epoch finished ! Loss: 0.16050506727053568
train_acc:0.3854602864100496 || test_acc:0.4759233141958358
Starting epoch 125/150.
Epoch finished ! Loss: 0.15994365857197687
train_acc:0.3860337814494925 || test_acc:0.46218078270056323
Starting epoch 126/150.
Epoch finished ! Loss: 0.1605855799638308
train_acc:0.3865679475575154 || test_acc:0.46869886106696745
Starting epoch 127/150.
Epoch finished ! Loss: 0.16037596934116805
train_acc:0.3871093506329464 || test_acc:0.4747278742536758
Starting epoch 128/150.
Epoch finished ! Loss: 0.15947067336394236
train_acc:0.38769456148882414 || test_acc:0.46701693894916907
Starting epoch 129/150.
Epoch finished ! Loss: 0.15895913197444037
train_acc:0.38832054703315255 || test_acc:0.4729419583309242
Starting epoch 130/150.
Epoch finished ! Loss: 0.1592663199855731
train_acc:0.3889137877968563 || test_acc:0.47267603537340136
Starting epoch 131/150.
Epoch finished ! Loss: 0.15915850206063345
train_acc:0.3894807317831754 || test_acc:0.4759920479478654
Starting epoch 132/150.
Epoch finished ! Loss: 0.15948968495313937
train_acc:0.39000898460783756 || test_acc:0.4782681734520286
Starting epoch 133/150.
Epoch finished ! Loss: 0.15987354918168142
train_acc:0.39049582721047216 || test_acc:0.47879242472146216
Starting epoch 134/150.
Epoch finished ! Loss: 0.15899631954156435
train_acc:0.3910359795858366 || test_acc:0.4796379779883658
Starting epoch 135/150.
Epoch finished ! Loss: 0.15849892107340005
train_acc:0.3915951165034573 || test_acc:0.4736050023169723
Starting epoch 136/150.
Epoch finished ! Loss: 0.15954559525618187
train_acc:0.39208863203636757 || test_acc:0.49159765924126636
Starting epoch 137/150.
Epoch finished ! Loss: 0.1588077906232614
train_acc:0.3926093122879466 || test_acc:0.4755979320377549
Starting epoch 138/150.
Epoch finished ! Loss: 0.1584410753387671
train_acc:0.3931500508632966 || test_acc:0.47276143606390086
Starting epoch 139/150.
Epoch finished ! Loss: 0.15952896384092477
train_acc:0.39362162817907287 || test_acc:0.4745406601890179
Starting epoch 140/150.
Epoch finished ! Loss: 0.15855421183200982
train_acc:0.3941338993014634 || test_acc:0.4802704780479464
Checkpoint 140 saved !
Starting epoch 141/150.
Epoch finished ! Loss: 0.1584664285182953
train_acc:0.39465432955977625 || test_acc:0.48531901463323873
Starting epoch 142/150.
Epoch finished ! Loss: 0.15862291134320772
train_acc:0.39514953561756544 || test_acc:0.4869202843969032
Starting epoch 143/150.
Epoch finished ! Loss: 0.15924408802619347
train_acc:0.3956171623936153 || test_acc:0.48671589428520484
Starting epoch 144/150.
Epoch finished ! Loss: 0.1585232586814807
train_acc:0.3961020466257255 || test_acc:0.486247931348561
Starting epoch 145/150.
Epoch finished ! Loss: 0.15799196637593782
train_acc:0.3966226965058945 || test_acc:0.49325284313039175
Starting epoch 146/150.
Epoch finished ! Loss: 0.15783328849535722
train_acc:0.39713791360501405 || test_acc:0.4915883401406825
Starting epoch 147/150.
Epoch finished ! Loss: 0.15736668098431367
train_acc:0.3976818430032588 || test_acc:0.4868374124723139
Starting epoch 148/150.
Epoch finished ! Loss: 0.15765422525314185
train_acc:0.39818696543294557 || test_acc:0.4794634209723615
Starting epoch 149/150.
Epoch finished ! Loss: 0.1576809327189739
train_acc:0.3986961384193002 || test_acc:0.5011982874476039
Starting epoch 150/150.
Epoch finished ! Loss: 0.15760234399483755
train_acc:0.39918090305643533 || test_acc:0.49740236122259335
END epoch150!
输出train每个epoch的loss值:
train_loss_epoch:[0.2074345275759697, 0.203783090871114, 0.2026076792524411, 0.2025472389963957, 0.20047383870069796, 0.1977322227679766, 0.1970054661998382, 0.19661698031883973, 0.1964181546981518, 0.19435437195576155, 0.1939917287001243, 0.1925974379365261, 0.19200260020219362, 0.19212372314471465, 0.19174265001828855, 0.19142395143325514, 0.19047389466028947, 0.18896214893231025, 0.1887347801373555, 0.1870169032078523, 0.18786631524562836, 0.187588896888953, 0.18635375568499932, 0.18618835107638285, 0.18639839841769293, 0.18381958168286544, 0.18494352812950426, 0.18366867762345535, 0.18428126321389124, 0.18260004486028963, 0.18279790190549997, 0.1811412165944393, 0.18141789791675714, 0.18091642226164156, 0.18165300901119524, 0.18066422641277313, 0.17884734846078432, 0.17863834420075783, 0.18020003804793724, 0.1796482916061695, 0.17811396087591463, 0.1771496287905253, 0.17697928043512198, 0.1771257330591862, 0.17650844156742096, 0.1756649951522167, 0.17627815157175064, 0.1759491150195782, 0.17481975372021014, 0.17545822262763977, 0.17446641394725212, 0.17460241054113096, 0.1742741001340059, 0.17458168933024773, 0.17452813513003862, 0.1735126060935167, 0.17314503571161857, 0.17264044571381348, 0.17217522859573364, 0.17174811088121855, 0.17218253245720497, 0.1715489047077986, 0.1716001285956456, 0.17030182767372865, 0.17137263657955024, 0.17106568068265915, 0.1709535620533503, 0.17035519159757173, 0.17079662932799414, 0.1708808455329675, 0.16889753307287508, 0.1699183279505143, 0.16949588805437088, 0.16856955794187692, 0.16824483642211327, 0.16807550134567115, 0.1678203115096459, 0.16786071199637193, 0.16752755011503512, 0.16796720601045168, 0.1671036034822464, 0.16763707594229624, 0.16769311290520889, 0.16759448785048264, 0.1666405378625943, 0.16542339496887648, 0.16568294339455092, 0.16538682064184776, 0.16577360950983488, 0.16548373836737412, 0.16550892018354857, 0.16548403925620592, 0.16575021296739578, 0.16504108160734177, 0.16463265281457168, 0.16373901355725068, 0.16535839896935683, 0.16445170113673577, 0.16331819731455582, 0.16466056326260933, 0.16396599721450072, 0.16394345920819503, 0.16370916767762259, 0.16320963031970537, 0.16312695351930764, 0.16330577089236334, 0.16327481946119896, 0.16224866589674583, 0.1620090426160739, 0.1627259082519091, 0.1618829323695256, 0.16170804374493086, 0.16192437192568412, 0.16206459414500457, 0.16185758205560538, 0.1609237348804107, 0.1612696309502308, 0.16052521020174026, 0.16063228536110657, 0.16049166195667708, 0.1610720192010586, 0.16068983192627245, 0.1615198655770375, 0.16050506727053568, 0.15994365857197687, 0.1605855799638308, 0.16037596934116805, 0.15947067336394236, 0.15895913197444037, 0.1592663199855731, 0.15915850206063345, 0.15948968495313937, 0.15987354918168142, 0.15899631954156435, 0.15849892107340005, 0.15954559525618187, 0.1588077906232614, 0.1584410753387671, 0.15952896384092477, 0.15855421183200982, 0.1584664285182953, 0.15862291134320772, 0.15924408802619347, 0.1585232586814807, 0.15799196637593782, 0.15783328849535722, 0.15736668098431367, 0.15765422525314185, 0.1576809327189739, 0.15760234399483755]
输出valid每个epoch的loss值:
valid_loss_epoch:[]
输出每个epoch的acc值:
train_acc_epoch:[0.27932615060254284, 0.28322156554184547, 0.2847435427078784, 0.28599866092419934, 0.28779029703033693, 0.2896429613458858, 0.29114389815849145, 0.2930045299020127, 0.29432114089026573, 0.2959916340154794, 0.2972975795456319, 0.2987222846769939, 0.3000171977721563, 0.3012301797853854, 0.3021397365691976, 0.3031575925148819, 0.304135089845711, 0.30515838772591175, 0.306125736823487, 0.30721168620801376, 0.308222862400972, 0.30905121912973876, 0.31002625500361836, 0.31081050617889827, 0.31162119088225176, 0.3127323124842886, 0.31359860240467835, 0.3146505473297833, 0.3154585743141472, 0.3164458813990067, 0.3173884295331177, 0.31841838782934573, 0.31926383048617885, 0.32020418848659865, 0.32096497201618795, 0.3217863524831262, 0.3228110080240505, 0.3237173525118794, 0.32448770111354674, 0.3253065845090883, 0.32619792131193764, 0.32713301203974005, 0.3279785860210416, 0.32883578527862195, 0.3297259272073704, 0.33064200893507517, 0.3315486472337272, 0.3324265965632971, 0.33330628668586265, 0.3341319598583846, 0.33501628363616587, 0.3358669907956203, 0.3366972858488509, 0.33746590678955596, 0.3382478132730009, 0.33906540846055283, 0.33991043867951604, 0.3407557914505193, 0.34157262344245315, 0.3423951892922143, 0.3432178016432514, 0.3440275414786207, 0.34486324848726413, 0.3456831586642441, 0.34645941526109075, 0.34723835073069415, 0.34796298757641764, 0.34875086049815, 0.3494766191350062, 0.35020429092176353, 0.35098199792044776, 0.35168558103858644, 0.352419529478127, 0.3531767882415493, 0.35392951987432436, 0.3546913931510804, 0.3554026622856409, 0.3561005036685311, 0.35685478151773387, 0.35754066814441077, 0.3582489649897671, 0.3589165649428054, 0.3596029482207766, 0.3602751133692171, 0.36097614649024545, 0.36172515303545516, 0.36244689886614423, 0.3631873318350077, 0.3638652418685668, 0.36452519976296177, 0.36517702796304596, 0.3658181434761394, 0.3664318513806177, 0.3671188404062498, 0.3677786916240404, 0.36849060960874674, 0.36907320719785036, 0.3697321507982301, 0.37044615762401634, 0.3710374962738257, 0.37164427202787004, 0.3722718655153018, 0.3728758665843605, 0.37353719932590873, 0.37415429612166295, 0.37476048256914357, 0.3753612842831394, 0.3759951412698322, 0.3766613906826468, 0.37723865374639975, 0.37787170517641344, 0.37849957061903033, 0.3790912177318055, 0.3796617941710696, 0.3802049912173493, 0.3808241242573479, 0.38140221306015226, 0.38201006313536967, 0.38262807463332904, 0.3832368054018088, 0.38378256343305495, 0.38436049602256117, 0.3848905619867847, 0.3854602864100496, 0.3860337814494925, 0.3865679475575154, 0.3871093506329464, 0.38769456148882414, 0.38832054703315255, 0.3889137877968563, 0.3894807317831754, 0.39000898460783756, 0.39049582721047216, 0.3910359795858366, 0.3915951165034573, 0.39208863203636757, 0.3926093122879466, 0.3931500508632966, 0.39362162817907287, 0.3941338993014634, 0.39465432955977625, 0.39514953561756544, 0.3956171623936153, 0.3961020466257255, 0.3966226965058945, 0.39713791360501405, 0.3976818430032588, 0.39818696543294557, 0.3986961384193002, 0.39918090305643533]
 valid_acc_epoch:[0.22016097136108517, 0.2664572819123179, 0.3014981200863307, 0.3087550482579793, 0.30390184242654034, 0.2977230930747212, 0.3100211929248867, 0.31496600558611154, 0.32954550483777967, 0.3211341050361573, 0.3206737163897404, 0.33183284195797297, 0.33388445831823976, 0.33698239825154114, 0.3275563337923393, 0.33428280268564725, 0.3344568678626166, 0.3431683594319114, 0.34184589515420205, 0.34229760643797713, 0.34410414498984043, 0.3430636151310396, 0.34713879002003106, 0.3465399835833611, 0.34878448429052994, 0.3486631299148875, 0.34804859015908957, 0.3544565673237951, 0.3554636845742411, 0.3554431312969182, 0.3636319789013291, 0.3575259313443966, 0.36255515658545545, 0.3736649736191552, 0.3675872930965306, 0.3679167112739744, 0.38139219196510576, 0.3666776258773829, 0.3690292734281549, 0.37521971694779116, 0.3800576689987439, 0.38284499207544453, 0.38511094878399654, 0.3711157771494361, 0.3764218197727322, 0.3759627537970887, 0.3828297589835934, 0.39234720056833394, 0.385319507311505, 0.386918132157358, 0.38748109921124363, 0.38714677576923073, 0.39928289850364823, 0.38940286925424933, 0.39357584987115346, 0.3968603293263598, 0.40029089517180744, 0.39808723061890516, 0.4033498149213054, 0.39075237186694706, 0.39717238697319124, 0.4059591511449911, 0.40579160793489216, 0.4074896232844831, 0.40178730510053623, 0.4096228625200907, 0.41532751972597953, 0.41674317311361414, 0.4251439981769521, 0.40912535858340393, 0.4212080469813079, 0.4169954706752583, 0.4277290122129148, 0.43172872941593277, 0.41835962188411147, 0.42854190713364315, 0.4219999308730986, 0.42741354185533326, 0.42744737806820976, 0.4247933513686604, 0.41899622830480227, 0.4215930295380669, 0.4351882042923465, 0.4455111513927036, 0.434697656128672, 0.4363591657898555, 0.4307339681840226, 0.44569945792265353, 0.4349989811147131, 0.45097397832246666, 0.44394349622832313, 0.4420868190511669, 0.4480442727332061, 0.4386854684424956, 0.44787592208943966, 0.44467418706863154, 0.4513445862995291, 0.45129901474120276, 0.4494853402191799, 0.4427695632105743, 0.44890476301638904, 0.4458656645092035, 0.45689465785979705, 0.4560876753990771, 0.45092831188033483, 0.4556504093619856, 0.45262368266719705, 0.4666368068218302, 0.4619935099886937, 0.45850809549180527, 0.45942352301473904, 0.46174741485484294, 0.46664758229983505, 0.4718868161484035, 0.46415707897373537, 0.45323869723179866, 0.469845467051867, 0.47237455950076784, 0.4808123240625379, 0.46540603379086387, 0.4676083038610468, 0.4808405593601088, 0.4776769093737709, 0.4759233141958358, 0.46218078270056323, 0.46869886106696745, 0.4747278742536758, 0.46701693894916907, 0.4729419583309242, 0.47267603537340136, 0.4759920479478654, 0.4782681734520286, 0.47879242472146216, 0.4796379779883658, 0.4736050023169723, 0.49159765924126636, 0.4755979320377549, 0.47276143606390086, 0.4745406601890179, 0.4802704780479464, 0.48531901463323873, 0.4869202843969032, 0.48671589428520484, 0.486247931348561, 0.49325284313039175, 0.4915883401406825, 0.4868374124723139, 0.4794634209723615, 0.5011982874476039, 0.49740236122259335]
输出最后一个epoch的值:
train_acc:0.39918090305643533 | valid_acc:0.49740236122259335

########## 最终k折交叉验证结果 ##########
train_acc_mean:0.3818
 valid_acc_mean:0.4965
 train_iou_mean:0.6260
 valid_iou_mean:0.6937
 train_dice_mean:0.4676
 valid_dice_mean:0.6569

train_acc_sd:0.0173 valid_acc_sd:0.0009
end_time: 2020-08-15 00:47:53
total_time: Thu Jan 01 09:44:52 1970
